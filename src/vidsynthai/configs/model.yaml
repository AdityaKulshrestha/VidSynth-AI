model_name: DeepSeek-R1
generation_config:
  temperature: 0.1
  frequency_penalty: 0 # Optional, Defaults to 0. Range: -2 to 2
  logit_bias: 
    2435: -100
    640: -100
  logprobs: True # Optional, Defaults to false
  top_logprobs: 2 # Optional. Range: 0 to 50
  max_tokens: 256 # Optional
  n : 1 # Optional, Defaults to 1
  presence_penalty : 0 # Optional, Defaults to 0. Range: -2 to 2
  response_format: 
    type: text  # Optional, Defaults to text
  stop: null # Optional, Defaults to null. Can take up to 4 sequences where the API will stop generating further tokens.
  stream: false # Optional, Defaults to false
  temperature: 0 # Optional, Defaults to 1. Range: 0 to 2
  top_p: 1 # Optional, Defaults to 1. We generally recommend altering this or temperature but not both.